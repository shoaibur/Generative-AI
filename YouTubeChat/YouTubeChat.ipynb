{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63c2f5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f216ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import textwrap\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b93b2a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class YouTubeChat:\n",
    "    def __init__(self, video_url):\n",
    "        self.db = self.create_db_from_youtube_video_url(video_url)\n",
    "        self.chat_history = []\n",
    "\n",
    "    def create_db_from_youtube_video_url(self, url):\n",
    "        loader = YoutubeLoader.from_youtube_url(url)\n",
    "        transcript = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "        docs = text_splitter.split_documents(transcript)\n",
    "        db = FAISS.from_documents(docs, embedding=OpenAIEmbeddings())\n",
    "        return db\n",
    "\n",
    "    def get_response_from_query(self, query, k=4):\n",
    "        docs = self.db.similarity_search(query, k=k)\n",
    "        docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "        chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "\n",
    "        template = \"\"\"\n",
    "            You are a helpful assistant that can answer questions about youtube videos\n",
    "            based on the video's transcript: {docs}\n",
    "            \n",
    "            Only use the factual information from the transcript to answer the question.\n",
    "            \n",
    "            If you feel like you don't have enough information to answer the question, say \"I don't know\".\n",
    "            \n",
    "            Your answers should be verbose and detailed. Limit your response in less than 100 words.\n",
    "        \"\"\"\n",
    "        system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "        \n",
    "        # Add previous chat history\n",
    "        messages = [system_message_prompt] + self.chat_history\n",
    "        human_message_prompt = HumanMessagePromptTemplate.from_template(\"Answer the following question: {question}\")\n",
    "        messages.append(human_message_prompt)\n",
    "        \n",
    "        chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "        \n",
    "        chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "        response = chain.run(question=query, docs=docs_page_content)\n",
    "        response = response.replace(\"\\n\", \"\")\n",
    "        \n",
    "        # Store the current query and response in chat history\n",
    "        self.chat_history.append(HumanMessagePromptTemplate.from_template(query))\n",
    "        self.chat_history.append(SystemMessagePromptTemplate.from_template(response))\n",
    "        \n",
    "        return response, docs\n",
    "    \n",
    "    def interactive_chat(self):\n",
    "        print(\"Type 'exit' to end the conversation.\")\n",
    "        while True:\n",
    "            query = input(\"You: \")\n",
    "            if query.lower() == 'exit':\n",
    "                break\n",
    "            response, _ = self.get_response_from_query(query)\n",
    "            print(\"Bot: \", textwrap.fill(response, width=85))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c509aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to end the conversation.\n",
      "You: Are they talking about microsoft? Respond in one word, either yes or no.\n",
      "Bot:  Yes.\n",
      "\n",
      "You: Can you provide more details?\n",
      "Bot:  Based on the transcript, there is no explicit mention of Microsoft. The conversation\n",
      "revolves around topics such as the potential existence of AGI (Artificial General\n",
      "Intelligence), the impact of digital intelligence, biases in AI models, and the\n",
      "importance of interacting with users and understanding their perspectives. While the\n",
      "discussion does not directly reference Microsoft, it is possible that the\n",
      "conversation could be relevant to the company's work in AI and technology. However,\n",
      "without further context, it is difficult to provide more specific details.\n",
      "\n",
      "You: exit\n"
     ]
    }
   ],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=L_Guz73e6fw\"\n",
    "youtub_chat = YouTubeChat(video_url)\n",
    "youtub_chat.interactive_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
